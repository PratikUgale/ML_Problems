{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie_review_sentiment_Analysis\n",
    "\n",
    "**Business Problem:** Create a model which Predict the moview review sentiment positive/negative on given Comments form User.\n",
    "\n",
    "**Dataset location :** [http://www.cs.cornell.edu/people/pabo/movie-review-data/](http://www.cs.cornell.edu/people/pabo/movie-review-data/)\n",
    "\n",
    "This is the dataset from cornell which contain positive and negative review about movie. this is the text classification basic problem.\n",
    "\n",
    "so lets get started\n",
    "\n",
    "we will import basis libraries require for analysis of dataset like\n",
    "\n",
    "1. numpy\n",
    "2. re\n",
    "3. nltk\n",
    "4. pandas\n",
    "5. sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import warnings\n",
    "\n",
    "#sklearn\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. from load_files we can load all file present in folder, it can load even from folder\n",
    "2. we will store data which we are using for training in X and target variable in Y\n",
    "3. now lets create padans dataframe from X and Y\n",
    "4. lets print first few rows of dataset to take overall look\n",
    "5. in dataset, almost 2000 rows are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arnold schwarzenegger has been an icon for act...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good films are hard to find these days . \\ngre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quaid stars as a man who has taken up the prof...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we could paraphrase michelle pfieffer's charac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kolya is one of the richest films i've seen in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  review\n",
       "0  arnold schwarzenegger has been an icon for act...       0\n",
       "1  good films are hard to find these days . \\ngre...       1\n",
       "2  quaid stars as a man who has taken up the prof...       1\n",
       "3  we could paraphrase michelle pfieffer's charac...       0\n",
       "4  kolya is one of the richest films i've seen in...       1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load files, \n",
    "review_rating=load_files('txt_sentoken/')\n",
    "X,Y= review_rating.data,review_rating.target\n",
    "data={'comments':X,'review':Y}\n",
    "data=pd.DataFrame(data)\n",
    "length=len(X)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we are applying some text cleaning procedure on dataset , so before doing changes we will take copy as pickle of dataset and work on pickle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump and load file from disk\n",
    "with open('X.pickle','wb') as f:\n",
    "    pickle.dump(X,f)\n",
    "    \n",
    "with open('Y.pickle','wb') as f:\n",
    "    pickle.dump(Y,f)\n",
    "    \n",
    "x1=open('X.pickle','rb')\n",
    "y1=open('Y.pickle','rb')\n",
    "\n",
    "x=pickle.load(x1)\n",
    "y=pickle.load(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lets look at the some of the random comments of user, it contain noisy data, we have to remove those noisy data to make data for training purpose\n",
    "2. we use python re library for cleaning and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess data using reguler expression\n",
    "data=[]\n",
    "for i in range (len(x)):\n",
    "    review_rating=re.sub(r'\\W',' ',X[i])\n",
    "    review_rating=review_rating.lower()\n",
    "    review_rating=re.sub(r'\\s[a-z]\\s+',' ',review_rating)\n",
    "    review_rating=re.sub(r'^[a-z]\\s+',' ',review_rating)\n",
    "    review_rating=re.sub(r'\\s+',' ',review_rating)\n",
    "    data.append(review_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. data is available in text format and now we need to convert it into vector form\n",
    "2. this dataset is smal in size, so we can directly apply tfidf vectorizer to convert text to vector form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF applying\n",
    "tfidf=TfidfTransformer()\n",
    "#transformer = TfidfTransformer()\n",
    "X = tfidf.fit_transform(X).toarray()\n",
    "\n",
    "tfidfv=TfidfVectorizer(max_features =length, min_df = 3, max_df = 0.6, stop_words = stopwords.words('english'))\n",
    "X=tfidfv.fit_transform(data).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. now we are good to split the dataset into training and testing set, we split it into 70:30 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.30, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. we dont know which algorithm is best suite fro this problem,\n",
    "2. we have list of classifier algorithm which we are going to apply on dataset\n",
    "3. it's look like LogisitcRegression  gives the best accuracy score almost ~83%\n",
    "4. Now we will tune the logisitc regression for achieving better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.30, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tfidfLogR', 82.928571428571431, 0.039311679730905769)\n",
      "('tfidfSVC', 51.571428571428577, 0.033775972621533965)\n",
      "('tfidfNB', 80.357142857142847, 0.043594841484763239)\n",
      "('tfidfDC', 62.214285714285708, 0.043501114224528896)\n",
      "('tfidfKNN', 65.214285714285708, 0.053361493416056456)\n",
      "('tfidfdAdaB', 75.928571428571416, 0.032269591423075755)\n",
      "('tfidfdGB', 77.785714285714278, 0.033571428571428578)\n",
      "('tfidfdRFR', 68.928571428571431, 0.04740726716012892)\n",
      "('tfidfdETR', 68.5, 0.029005629291781382)\n"
     ]
    }
   ],
   "source": [
    "model2=[]\n",
    "model2.append(('tfidfLogR',Pipeline([('LogR',LogisticRegression())])))\n",
    "model2.append(('tfidfSVC',Pipeline([('SVC',SVC())])))\n",
    "model2.append(('tfidfNB',Pipeline([('NB',MultinomialNB())])))\n",
    "model2.append(('tfidfDC',Pipeline([('DC',DecisionTreeClassifier())])))\n",
    "model2.append(('tfidfKNN',Pipeline([('KNN',KNeighborsClassifier())])))\n",
    "model2.append(('tfidfdAdaB',Pipeline([('AdaB',AdaBoostClassifier())])))\n",
    "model2.append(('tfidfdGB',Pipeline([('GB',GradientBoostingClassifier())])))\n",
    "model2.append(('tfidfdRFR',Pipeline([('RFR',RandomForestClassifier())])))\n",
    "model2.append(('tfidfdETR',Pipeline([('ETR',ExtraTreesClassifier())])))\n",
    "\n",
    "names=[]\n",
    "result=[]\n",
    "for name , algo in model2:\n",
    "    kfold=KFold(n_splits=10, random_state=7)\n",
    "    cv_result=cross_val_score(algo,X_train,Y_train,scoring='accuracy',cv=kfold,verbose=0,n_jobs=-1)\n",
    "    result.append(cv_result)\n",
    "    names.append(name)\n",
    "    print(name,cv_result.mean()*100,cv_result.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best result for gridSearch', 0.82928571428571429, {'multi_class': 'ovr', 'solver': 'newton-cg'})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#C_val=np.array([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,1.2,1.5,1.8,2.0])\n",
    "multi_class =['ovr', 'auto']\n",
    "solver =['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "par_grid=dict(multi_class=multi_class,solver=solver)\n",
    "fitmodel=LogisticRegression()\n",
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "grid=GridSearchCV(estimator=fitmodel,param_grid=par_grid,scoring='accuracy',cv=kfold)\n",
    "grid_result=grid.fit(X_train,Y_train)\n",
    "print(\"Best result for gridSearch\",grid_result.best_score_,grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. still after tuning , we got the same results, now we will train our model on Logisitc regresion and predict the feauture review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.861666666667\n",
      "[[249  54]\n",
      " [ 29 268]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86       303\n",
      "           1       0.83      0.90      0.87       297\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       600\n",
      "   macro avg       0.86      0.86      0.86       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model=LogisticRegression()\n",
    "model.fit(X_train,Y_train)\n",
    "decision=model.predict(X_test)\n",
    "finalScore=accuracy_score(decision,Y_test)\n",
    "finalScore1=confusion_matrix(decision,Y_test)\n",
    "finalScore2=classification_report(decision,Y_test)\n",
    "print(finalScore)\n",
    "print(finalScore1)\n",
    "print(finalScore2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. after training and prediction on testing dataset. wew got almost 86% accuracy score \n",
    "2. confusion_score also look good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
